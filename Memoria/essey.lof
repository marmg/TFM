\babel@toc {spanish}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Word Embeddings\relax }}{3}{figure.caption.6}
\contentsline {figure}{\numberline {2.2}{\ignorespaces \emph {LSTM} Recurrent Neural Networks.\relax }}{4}{figure.caption.8}
\contentsline {figure}{\numberline {2.3}{\ignorespaces \emph {Encoder-Decoder} architecture.\relax }}{4}{figure.caption.10}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of the \emph {Attention} mechanism in machine translation. It can be seen as the \emph {Attention} mechanism focus only on the words being translated and the relevant ones instead in the whole sentence.\relax }}{5}{figure.caption.12}
\contentsline {figure}{\numberline {2.5}{\ignorespaces \emph {Self-Attention} mechanism.\relax }}{6}{figure.caption.14}
\contentsline {figure}{\numberline {2.6}{\ignorespaces \emph {Transformer} architecture.\relax }}{6}{figure.caption.16}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Cronological view of a sample of language models. It can be seen that since \emph {BERT} the number of language models released has grown exponentially.\relax }}{8}{figure.caption.21}
\contentsline {figure}{\numberline {2.8}{\ignorespaces \emph {GPT-2} architecture.\relax }}{9}{figure.caption.28}
\contentsline {figure}{\numberline {2.9}{\ignorespaces \emph {T-NLG}, \emph {DeepSpeed} and \emph {ZeRo}.\relax }}{11}{figure.caption.38}
\contentsline {figure}{\numberline {2.10}{\ignorespaces \emph {BART} architecture.\relax }}{12}{figure.caption.42}
\contentsline {figure}{\numberline {2.11}{\ignorespaces \emph {ELECTRA} architecture.\relax }}{13}{figure.caption.50}
\contentsline {figure}{\numberline {2.12}{\ignorespaces Comparison of \emph {ELECTRA} with other \emph {LM}.\relax }}{14}{figure.caption.52}
\contentsline {figure}{\numberline {2.13}{\ignorespaces Question Answering system working in the search engine \emph {Google}.\relax }}{15}{figure.caption.56}
\contentsline {figure}{\numberline {2.14}{\ignorespaces Question Answering common modules.\relax }}{15}{figure.caption.59}
\contentsline {figure}{\numberline {2.15}{\ignorespaces Workflow proposed by Ahmed.\relax }}{16}{figure.caption.62}
\contentsline {figure}{\numberline {2.16}{\ignorespaces \emph {XAI} Visualization examples.\relax }}{27}{figure.caption.111}
\contentsline {figure}{\numberline {2.17}{\ignorespaces Functioning of \emph {LIME}.\relax }}{32}{figure.caption.135}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces \emph {BertViz} examples.\relax }}{38}{figure.caption.153}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Example of \emph {BertViz}.\relax }}{39}{figure.caption.162}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces \emph {LIME} result for the first experiment with original example.\relax }}{47}{figure.caption.172}
\contentsline {figure}{\numberline {4.2}{\ignorespaces \emph {Attention} heatmap for correct answer.\relax }}{48}{figure.caption.179}
\contentsline {figure}{\numberline {4.3}{\ignorespaces \emph {Attention} Heatmaps.\relax }}{48}{figure.caption.181}
\contentsline {figure}{\numberline {4.4}{\ignorespaces \emph {BertViz} Head View of Question to Answers.\relax }}{49}{figure.caption.184}
\contentsline {figure}{\numberline {4.5}{\ignorespaces \emph {BertViz} layer 11, head 2.\relax }}{50}{figure.caption.186}
\contentsline {figure}{\numberline {4.6}{\ignorespaces \emph {BertViz} Model View of Question to Answers A and B.\relax }}{50}{figure.caption.188}
\contentsline {figure}{\numberline {4.7}{\ignorespaces To look at a single head in the Model View of \emph {BertViz}.\relax }}{50}{figure.caption.190}
\contentsline {figure}{\numberline {4.8}{\ignorespaces Explanation of GPT3 for the Example 1.\relax }}{53}{figure.caption.197}
\contentsline {figure}{\numberline {4.9}{\ignorespaces Explanation of GPT3.\relax }}{54}{figure.caption.200}
\contentsline {figure}{\numberline {4.10}{\ignorespaces Wrong prediction of GPT3.\relax }}{54}{figure.caption.202}
\contentsline {figure}{\numberline {4.11}{\ignorespaces Wrong explanation of GPT3.\relax }}{55}{figure.caption.203}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Explanation of all options given by \emph {LIME}\relax }}{58}{figure.caption.208}
\addvspace {10\p@ }
