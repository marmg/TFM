{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.utils_multiple_choice import convert_examples_to_features, InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset race (/home/marcos/.cache/huggingface/datasets/race/middle/0.1.0/a7d1fac780e70c0e75bca35e9f2f8cfc1411edd18ffd6858ddce56f70dfb1e7c)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained(\"../assets/models/bb_race_m/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../assets/models/bb_race_m\")\n",
    "\n",
    "dataset = load_dataset(\"race\", \"middle\")\n",
    "test = dataset['test']\n",
    "\n",
    "label_list = [\"0\", \"1\", \"2\", \"3\"]\n",
    "label_map = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\"\n",
    "}\n",
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(article_, question_, options_, real_label=None):\n",
    "    examples = [InputExample(\n",
    "        example_id=\"pred\",\n",
    "        question=question_,\n",
    "        contexts=[article_, article_, article_, article_],  # this is not efficient but convenient\n",
    "        endings=[options_[0], options_[1], options_[2], options_[3]],\n",
    "        label=str(ord(real_label) - ord(\"A\")) if real_label else \"0\"\n",
    "    )]\n",
    "    \n",
    "    feature = convert_examples_to_features(\n",
    "        examples,\n",
    "        label_list,\n",
    "        max_seq_length,\n",
    "        tokenizer\n",
    "    )[0]\n",
    "    \n",
    "    features = {\n",
    "        'input_ids': torch.tensor([feature.input_ids]),\n",
    "        'attention_mask': torch.tensor([feature.attention_mask]),\n",
    "        'token_type_ids': torch.tensor([feature.token_type_ids]),\n",
    "    } \n",
    "    \n",
    "    result = model.forward(features['input_ids'], features['attention_mask'], features['token_type_ids'])[0][0]\n",
    "    \n",
    "#     print(f\"Scores: {[float(abs(x)) for x in result]}\")\n",
    "    \n",
    "    return np.array([float(abs(x)) for x in result]).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 67.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: Take a class at Dulangkou School, and you'll see lots of things different from other schools, You can see the desks are not in rows and students sit in groups. They put their desks together so they're facing each other. How can they see the blackboard? There are three blackboards on the three walls of the classroom!\n",
      "The school calls the new way of learning \"Tuantuanzuo\", meaning sitting in groups. Wei Liying, a Junior 3 teacher, said it was to give students more chances to communicate.\n",
      "Each group has five or six students, according to Wei, and they play different roles .There is a team leader who takes care of the whole group. There is a \"study leader\"who makes sure that everyone finishes their homework. And there is a discipline leader who makes sure that nobody chats in class.\n",
      "Wang Lin is a team leader. The 15-year-old said that having to deal with so many things was tiring.\n",
      "\"I just looked after my own business before,\"said Wang. \"But now I have to think about my five group members.\"\n",
      "But Wang has got used to it and can see the benefits now.\n",
      "\"I used to speak too little. But being a team leader means you have to talk a lot. You could even call me an excellent speaker today.\"\n",
      "Zhang Qi, 16, was weak in English. She used to get about 70 in English tests. But in a recent test, Zhang got a grade of more than 80.\n",
      "\"I rarely  asked others when I had problems with my English tests. But now I can ask the team leader or study leader. They are really helpful.\"\n",
      "Question: A discipline leader is supposed to  _  .\n",
      "Options: ['take care of the whole group', 'make sure that everybody finishes homework', 'make sure that nobody chats in class', 'collect all the homework and hand it in to teachers']\n",
      "Prediction: C\n",
      "Real answer: C\n"
     ]
    }
   ],
   "source": [
    "ex = test[0]\n",
    "\n",
    "article = ex['article']\n",
    "question = ex['question']\n",
    "options = ex['options']\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 66.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is a discipline leader supposed to?\n",
      "Options: ['take care of the whole group', 'make sure that everybody finishes homework', 'make sure that nobody chats in class', 'collect all the homework and hand it in to teachers']\n",
      "Prediction: A\n",
      "Real answer: C\n"
     ]
    }
   ],
   "source": [
    "ex = test[0]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"What is a discipline leader supposed to?\"\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "# print(f\"Article: {article}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 83.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is a discipline leader?\n",
      "Options: ['A person supposed to take care of the whole group', 'A person supposed to make sure that everybody finished homework', 'A person supposed to make sure that nobody chats in class', 'A person supposed to collect all the homework and hand it in to teachers']\n",
      "Prediction: B\n",
      "Real answer: C\n"
     ]
    }
   ],
   "source": [
    "ex = test[0]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"What is a discipline leader?\"\n",
    "options = [\n",
    "    \"A person supposed to take care of the whole group\",\n",
    "    \"A person supposed to make sure that everybody finished homework\",\n",
    "    \"A person supposed to make sure that nobody chats in class\",\n",
    "    \"A person supposed to collect all the homework and hand it in to teachers\"\n",
    "]\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "# print(f\"Article: {article}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 83.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is an orderliness leader?\n",
      "Options: ['A person supposed to take care of the whole group', 'A person supposed to make sure that everybody finished homework', 'A person supposed to make sure that nobody chats in class', 'A person supposed to collect all the homework and hand it in to teachers']\n",
      "Prediction: C\n",
      "Real answer: C\n"
     ]
    }
   ],
   "source": [
    "ex = test[0]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"What is an orderliness leader?\"\n",
    "options = [\n",
    "    \"A person supposed to take care of the whole group\",\n",
    "    \"A person supposed to make sure that everybody finished homework\",\n",
    "    \"A person supposed to make sure that nobody chats in class\",\n",
    "    \"A person supposed to collect all the homework and hand it in to teachers\"\n",
    "]\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "# print(f\"Article: {article}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 97.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: A traveler came out of the airport. There were a lot of taxis. He asked every taxi driver about his name. Then he took the third one. It cost 5 dollars from the airport to the hotel. \"How much does it cost for the whole day?\" The man asked. \"100 dollars,\" said the taxi driver. This was very dear  , but the man said it was OK.\n",
      "The taxi driver took the man everywhere. He showed him all the parks and museums in the city. In the evening they went back to the hotel. The traveler gave the taxi driver 100 dollars and said, \"What about tomorrow?\" The taxi driver looked at the man and said, \"Tomorrow is another 100 dollars.\" And the man said, \"That's OK! See you tomorrow.\" The taxi driver was very pleased.\n",
      "The next day the taxi driver took the traveler everywhere again. They visited all the parks and museums again. And in the evening they went back to the hotel. The man gave the taxi driver 100 dollars again and said, \"I'm going home tomorrow.\" The driver was sorry because he liked the traveler and 100 dollars a day was a lot of money. \"So you are going home. Where do you come from?\" He asked. \"I come from New York.\" \"New York,\" the taxi driver said, \"I have a sister in New York. Her name is Susan. Do you know her?\" \"Of course I know her. She gave me 200 dollars for you!\"\n",
      "Question: Where did the traveler come from?\n",
      "Options: ['England', 'America', 'Canada', 'France']\n",
      "Prediction: A\n",
      "Real answer: B\n"
     ]
    }
   ],
   "source": [
    "ex = test[86]\n",
    "\n",
    "article = ex['article']\n",
    "question = ex['question']\n",
    "options = ex['options']\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "print(f\"Article: {article}\")\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 97.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The traveler came from _ .\n",
      "Options: ['England', 'America', 'Canada', 'France']\n",
      "Prediction: C\n",
      "Real answer: B\n"
     ]
    }
   ],
   "source": [
    "ex = test[86]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"The traveler came from _ .\"\n",
    "options = ex['options']\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 72.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The traveler _ .\n",
      "Options: ['came from England', 'came from America', 'came from Canada', 'came from France']\n",
      "Prediction: C\n",
      "Real answer: B\n"
     ]
    }
   ],
   "source": [
    "ex = test[86]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"The traveler _ .\"\n",
    "options = [\n",
    "    \"came from England\",\n",
    "    \"came from America\",\n",
    "    \"came from Canada\",\n",
    "    \"came from France\"\n",
    "]\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mod c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert examples to features: 1it [00:00, 79.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The visitor _ .\n",
      "Options: ['came from England', 'came from America', 'came from Canada', 'came from France']\n",
      "Prediction: C\n",
      "Real answer: B\n"
     ]
    }
   ],
   "source": [
    "ex = test[86]\n",
    "\n",
    "article = ex['article']\n",
    "question = \"The visitor _ .\"\n",
    "options = [\n",
    "    \"came from England\",\n",
    "    \"came from America\",\n",
    "    \"came from Canada\",\n",
    "    \"came from France\"\n",
    "]\n",
    "real_label = ex['answer']\n",
    "\n",
    "result = predict(article, question, options, real_label)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Options: {options}\")\n",
    "print(f\"Prediction: {label_map[result]}\")\n",
    "print(f\"Real answer: {real_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TFM]",
   "language": "python",
   "name": "conda-env-TFM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
